Number,Title,Body,Closed,Merged,MergedAt,ClosedAt,ReviewComments,Participants,Comments,Files,Additions,Deletions,Modifications,TimeToAnalysis
30453,Add `paths` filter to avoid the chance of being triggered,1012,True,True,2024-04-24T14:58:54Z,2024-04-24T14:58:54Z,2,3,1,1,2,15,17,9399.348115
30421,[SegGPT] Fix loss calculation,1094,True,True,2024-04-24T14:24:34Z,2024-04-24T14:24:34Z,2,2,2,2,89,16,105,97328.348828
30418,fix jamba slow foward for multi-gpu,1237,True,True,2024-04-24T12:19:08Z,2024-04-24T12:19:08Z,2,3,2,1,2,1,3,100335.348828
30435,fix uncaught init of linear layer in clip's/siglip's for image classification models,1126,True,True,2024-04-24T12:03:31Z,2024-04-24T12:03:31Z,1,4,8,2,10,0,10,79013.348828
30414,Fix attn mask for static cache,378,True,False,,2024-04-24T10:37:11Z,1,4,7,4,20,0,20,106078.348828
30444,[tests] make test device-agnostic,1251,True,True,2024-04-24T10:21:27Z,2024-04-24T10:21:28Z,1,2,0,1,14,16,30,46681.348828
30337,Add messages to agents (#5),99,True,True,2024-04-24T09:56:25Z,2024-04-24T09:56:25Z,1,3,2,3,158,45,203,451650.348828
30440,[`Llava`] + CIs fix red cis and llava integration tests,65,True,True,2024-04-24T08:51:35Z,2024-04-24T08:51:35Z,5,4,2,2,5,13,18,62170.348828
30436,Fix YOLOS image processor resizing,1422,True,True,2024-04-24T08:50:17Z,2024-04-24T08:50:17Z,1,3,2,2,24,7,31,78945.348828
29356,[`_unmask_unattended`] Refactor,278,True,False,,2024-04-24T08:19:36Z,4,2,1,5,34,42,76,4805493.349861
30334,Add llama3,42,True,True,2024-04-24T08:11:19Z,2024-04-24T08:11:19Z,1,7,6,7,279,28,307,463194.349861
30341,New model PR needs green (slow tests) CI,348,True,True,2024-04-24T07:52:55Z,2024-04-24T07:52:55Z,21,4,2,2,221,0,221,443628.349861
30420,Remove mentions of models in the READMEs and link to the documentation page in which they are featured.,120,True,True,2024-04-24T07:38:31Z,2024-04-24T07:38:31Z,2,4,4,14,14,3625,3639,97645.349861
30424,Remove add-new-model in favor of add-new-model-like,180,True,True,2024-04-24T07:38:19Z,2024-04-24T07:38:19Z,2,4,2,36,39,14439,14478,95713.349861
30429,Remove task guides auto-update in favor of links towards task pages,128,True,True,2024-04-24T07:38:10Z,2024-04-24T07:38:10Z,1,3,2,53,46,508,554,93024.349861
29694,Respect `add_prefix_space` option in `LlamaTokenizerFast`,1267,True,False,,2024-04-23T21:13:02Z,3,4,11,1,4,0,4,3336224.349861
28881,[`LlamaTokenizerFast`] Refactor default llama,783,True,True,2024-04-23T21:13:00Z,2024-04-23T21:13:00Z,5,4,2,5,142,31,173,6779708.349861
30376,Make EosTokenCriteria compatible with mps,783,True,True,2024-04-23T13:23:52Z,2024-04-23T13:23:52Z,4,7,7,1,12,1,13,246745.349861
29876,Add beam search visualizer to the doc,110,True,True,2024-03-28T09:54:08Z,2024-03-28T09:54:08Z,2,4,5,1,7,1,8,2519936.911214
30353,Fix use_cache for xla fsdp,815,True,True,2024-04-23T17:01:35Z,2024-04-23T17:01:35Z,2,4,6,1,6,0,6,418270.911214
30405,Rename torch.run to torchrun,481,True,True,2024-04-23T16:04:17Z,2024-04-23T16:04:17Z,1,3,1,1,1,1,2,137892.911214
30426,Remove old TF port docs,124,True,True,2024-04-23T15:06:21Z,2024-04-23T15:06:21Z,1,3,1,14,0,1305,1305,93667.911214
30278,Fix LayoutLMv2 init issue and doctest,678,True,True,2024-04-23T13:33:17Z,2024-04-23T13:33:18Z,12,3,2,1,15,12,27,677775.911214
30133,fix for itemsize => element_size() for torch backwards compat,263,True,True,2024-04-23T13:00:28Z,2024-04-23T13:00:28Z,9,8,5,1,7,6,13,1345042.911214
30408,[tests] add `require_torch_sdpa` for test that needs sdpa support,484,True,True,2024-04-23T09:39:38Z,2024-04-23T09:39:38Z,5,5,1,1,2,0,2,119084.911214
26681,Generate: New `Cache` abstraction and Attention Sinks support,1455,True,True,2023-12-08T08:00:18Z,2023-12-08T08:00:18Z,83,14,32,14,962,195,1157,17134626.911214
30068,"Fix on ""cache position"" for assisted generation",1090,True,True,2024-04-23T11:23:36Z,2024-04-23T11:23:36Z,14,4,4,4,77,38,115,1652396.911214
30402,Jax: scipy version pin,1505,True,True,2024-04-23T09:42:17Z,2024-04-23T09:42:17Z,1,3,1,2,3,1,4,159627.911214
30406,fix: link to HF repo/tree/revision when a file is missing,1105,True,True,2024-04-23T09:05:57Z,2024-04-23T09:05:57Z,1,2,0,1,1,1,2,119981.911214
30297,Using variables (#4),193,True,True,2024-04-23T09:00:38Z,2024-04-23T09:00:38Z,1,2,1,3,14,3,17,597813.911214
30365,remove redundant logging from longformer,375,True,True,2024-04-23T08:57:03Z,2024-04-23T08:57:03Z,3,4,2,1,1,1,2,335641.911214
30364,[Grounding DINO] Add support for cross-attention in GroundingDinoMultiHeadAttention,685,True,True,2024-04-23T08:56:15Z,2024-04-23T08:56:15Z,6,2,2,2,38,3,41,338422.911214
29930,Llama: fix custom 4D masks,471,True,False,,2024-04-23T08:51:22Z,7,4,12,7,309,309,618,2348618.911214
30254,Improve logging (#3),430,True,True,2024-04-23T08:38:01Z,2024-04-23T08:38:01Z,2,2,0,2,3,3,6,780605.911214
30269,Add inputs embeds in generation,322,True,True,2024-04-23T08:14:48Z,2024-04-23T08:14:48Z,7,4,3,4,63,32,95,698058.911214
29652,refactor: replace magic strings with constant `SPIECE_UNDERLINE`,608,True,False,,2024-04-23T08:04:17Z,1,2,4,87,891,361,1252,3566778.062187
30262,[FEAT]: EETQ quantizer support,1043,True,True,2024-04-22T19:38:58Z,2024-04-22T19:38:58Z,20,5,12,14,570,2,572,718510.062187
30318,show `-rs` to show skip reasons,50,True,True,2024-04-23T06:05:42Z,2024-04-23T06:05:42Z,1,3,1,3,5,5,10,523321.062187
30379,Enable multi-device for more models,4316,True,True,2024-04-22T09:57:27Z,2024-04-22T09:57:28Z,1,2,0,5,5,0,5,206217.062187
29776,Add support for `torch_dtype` in the run_mlm example,196,True,True,2024-03-21T15:09:35Z,2024-03-21T15:09:35Z,1,3,0,1,17,0,17,2956650.062187
29791,[docs] LLM inference,430,True,True,2024-04-22T19:41:51Z,2024-04-22T19:41:51Z,14,9,2,2,328,0,328,2914023.062187
30121,Add sdpa and fa2 the Wav2vec2 family. ,537,True,True,2024-04-22T17:30:38Z,2024-04-22T17:30:38Z,15,5,7,11,2407,101,2508,1395744.062187
30326,Fix DETA save_pretrained,2224,True,True,2024-04-22T16:11:13Z,2024-04-22T16:11:13Z,4,4,2,3,44,3,47,508268.062187
30389,Jamba: fix left-padding test,136,True,True,2024-04-22T16:02:55Z,2024-04-22T16:02:55Z,2,4,1,1,1,1,2,188202.062187
30372,Fix layerwise GaLore optimizer hard to converge with warmup scheduler ,690,True,True,2024-04-22T16:00:26Z,2024-04-22T16:00:26Z,2,4,1,1,2,3,5,265605.062187
27478,feat: add flash_attn 2 to bert,651,True,False,,2024-03-11T08:05:56Z,1,6,11,20,266,28,294,14037311.062187
28932,Terminator strings for generate(),1232,True,True,2024-04-22T13:13:04Z,2024-04-22T13:13:04Z,36,5,18,6,529,4,533,6556266.062187
30343,Update docstrings for text generation pipeline,134,True,True,2024-04-22T13:01:30Z,2024-04-22T13:01:30Z,3,4,1,1,22,8,30,440772.062187
30380,"`Llama` family, fix `use_cache=False` generation",34,True,True,2024-04-22T12:42:57Z,2024-04-22T12:42:57Z,1,3,2,4,40,12,52,198245.062187
30002,Add FSDP config for CPU RAM efficient loading through accelerate,1064,True,True,2024-04-22T12:15:28Z,2024-04-22T12:15:28Z,6,5,4,2,21,1,22,1895037.062187
30187,GenerationConfig: warn if pad token is negative,372,True,True,2024-04-22T10:31:39Z,2024-04-22T10:31:39Z,3,4,1,1,5,0,5,1123985.062187
30207,Enable multi-device for some models,25431,True,True,2024-04-19T08:24:44Z,2024-04-19T08:24:44Z,1,3,8,27,42,4,46,1070141.062187
29795,Nits for model docs,50,True,True,2024-04-22T09:41:03Z,2024-04-22T09:41:03Z,1,3,1,2,5,5,10,2907943.940727
29937,Update documentation for agents,81,True,True,2024-04-22T09:07:49Z,2024-04-22T09:07:49Z,20,4,7,12,679,1151,1830,2338332.940727
29265,Add token type ids to CodeGenTokenizer,81,True,True,2024-04-17T10:19:18Z,2024-04-17T10:19:18Z,11,4,16,4,127,0,127,5229884.940727
26963,[RWKV] Add RWKV5 model and RWKVWorldTokenizer,349,True,False,,2024-04-22T08:07:43Z,34,6,48,30,2573,4,2577,16155959.940727
29677,Adding FlaxNoRepeatNGramLogitsProcessor,2521,True,True,2024-04-02T09:39:33Z,2024-04-02T09:39:33Z,14,5,3,4,135,2,137,3459330.941371
23342,Add TF swiftformer,756,True,True,2024-04-19T17:31:44Z,2024-04-19T17:31:44Z,37,4,99,11,1244,20,1264,30049022.941371
30232,[Grounding DINO] Add resources,78,True,True,2024-04-19T19:03:07Z,2024-04-19T19:03:07Z,2,3,2,2,23,0,23,974493.941371
29770,Disable torch.autocast in RotaryEmbedding of Gemma and LLaMa for meta device,764,True,False,,2024-04-19T18:04:18Z,1,3,5,2,2,2,4,2968139.941371
30085,fix learning rate display in trainer when using galore optimizer,934,True,True,2024-04-08T13:54:12Z,2024-04-08T13:54:12Z,2,3,1,1,1,1,2,1554672.941371
30086,Fix accelerate kwargs for versions <0.28.0,916,True,True,2024-04-10T14:36:44Z,2024-04-10T14:36:44Z,1,3,2,1,3,2,5,1554243.941371
30299,Fix config + attn_implementation in AutoModelForCausalLM.from_pretrained,559,True,True,2024-04-19T16:45:53Z,2024-04-19T16:45:53Z,8,5,5,2,39,1,40,595236.941371
30016,Do not remove half seq length in generation tests,875,True,True,2024-04-19T16:32:52Z,2024-04-19T16:32:53Z,6,4,3,10,180,261,441,1829816.941371
29933,Update unwrap from accelerate,130,True,True,2024-04-19T16:05:34Z,2024-04-19T16:05:34Z,11,6,4,3,36,18,54,2346480.941371
30336,Restore casting of masked_spec_embed,111,True,True,2024-04-19T15:18:36Z,2024-04-19T15:18:36Z,2,4,1,11,22,22,44,455557.941371
30143,Add recurrent gemma,54,True,True,2024-04-10T14:59:13Z,2024-04-10T14:59:13Z,9,9,2,32,2001,1,2002,1301234.941371
30152,[Whisper] Fix slow tests,373,True,True,2024-04-19T11:21:46Z,2024-04-19T11:21:46Z,7,4,8,1,141,127,268,1271741.859609
30338,Pipeline: fix `pad_token_id` again,247,True,True,2024-04-19T11:04:12Z,2024-04-19T11:04:12Z,2,4,3,1,1,1,2,451607.859609
29459,Move `eos_token_id` to stopping criteria,797,True,True,2024-03-27T12:18:10Z,2024-03-27T12:18:10Z,22,6,9,6,215,76,291,4329224.859609
30260,[Feature Extractors] Fix kwargs to pre-trained,2756,True,True,2024-04-19T10:16:09Z,2024-04-19T10:16:09Z,1,3,1,2,18,4,22,769820.859609
29396,Soft reboot Agents & Tools,2039,True,False,,2024-04-19T10:06:48Z,9,4,9,23,969,1141,2110,4658428.859609
30135,feat: Upgrade Weights & Biases callback,790,True,True,2024-04-19T10:03:32Z,2024-04-19T10:03:32Z,1,3,2,1,96,5,101,1331959.859609
29594,[UDOP] Add special tokens to tokenizer,121,True,True,2024-04-19T07:06:01Z,2024-04-19T07:06:01Z,6,3,7,2,43,3,46,3795179.859609
30322,Avoid `jnp` import in `utils/generic.py` ,83,True,True,2024-04-18T17:46:46Z,2024-04-18T17:46:46Z,1,3,3,1,8,4,12,518333.859609
30321,Fix `AssertionError` in clip conversion script,1853,True,True,2024-04-18T18:18:03Z,2024-04-18T18:18:03Z,1,3,1,4,12,1,13,521111.859609
30190,🚨🚨🚨Deprecate `evaluation_strategy` to `eval_strategy`🚨🚨🚨,1414,True,True,2024-04-18T16:49:43Z,2024-04-18T16:49:43Z,2,4,6,116,214,203,417,1121187.859609
30319,Fix test transposing image with EXIF Orientation tag,838,True,True,2024-04-18T16:41:20Z,2024-04-18T16:41:20Z,3,4,3,1,25,11,36,522885.859609
30320,disable use_cache if using gradient checkpointing,872,True,True,2024-04-18T16:18:03Z,2024-04-18T16:18:03Z,1,2,0,1,6,0,6,522486.859609
29921,Add DBRX Model,814,True,True,2024-04-18T13:18:52Z,2024-04-18T13:18:52Z,112,17,42,30,2430,31,2461,2394278.859609
30310,fix Parameter dtype in audio models,946,True,True,2024-04-18T15:18:01Z,2024-04-18T15:18:01Z,2,5,4,11,33,33,66,539771.859609
30285,Fix: remove `pad token id` in pipeline forward arguments ,92,True,True,2024-04-18T14:31:32Z,2024-04-18T14:31:33Z,3,4,1,1,6,6,12,629842.859609
30313,Fix missing `prev_ci_results`,388,True,True,2024-04-18T14:10:25Z,2024-04-18T14:10:25Z,4,4,1,1,9,9,18,535886.867677
30317,FIX: Fixes unexpected behaviour for Llava / LLama & AWQ Fused modules + revert #30070 at the same time,373,True,True,2024-04-18T13:51:17Z,2024-04-18T13:51:17Z,9,5,2,7,230,75,305,526572.86787
28065,Cache: `Bart` and related architectures support `Cache` objects,1765,True,False,,2024-04-18T13:10:27Z,1,3,5,42,3510,2436,5946,11332658.052572
29221,Static Cache: no mandatory `cache_positions` input,691,True,False,,2024-04-18T13:09:34Z,9,4,8,5,242,64,306,5345471.052572
30311,Do not drop mask with SDPA for more cases,117,True,True,2024-04-18T12:37:09Z,2024-04-18T12:37:09Z,4,3,3,1,6,2,8,539681.052572
30273,Fix RecurrentGemma device_map,599,True,True,2024-04-18T09:52:10Z,2024-04-18T09:52:10Z,6,3,2,1,8,4,12,691832.052572
28094,[`Add Mamba`] Adds support for the `Mamba` models,1819,True,True,2024-03-05T11:01:06Z,2024-03-05T11:01:07Z,10,7,29,26,1583,5,1588,11219013.052572
30303,Add atol for sliding window test,360,True,True,2024-04-18T09:08:34Z,2024-04-18T09:08:34Z,1,3,1,1,1,1,2,582394.052572
29943,Add jamba,118,True,True,2024-04-18T09:04:02Z,2024-04-18T09:04:02Z,48,4,4,35,3161,26,3187,2330651.052572
30290,Fix all torch pipeline failures except one,83,True,True,2024-04-18T08:35:43Z,2024-04-18T08:35:43Z,6,3,1,4,25,23,48,624210.052572
28538,[`gradient_checkpointing`] default to use it for torch 2.3,72,True,True,2024-02-20T01:23:25Z,2024-02-20T01:23:25Z,1,5,6,1,1,1,2,8547581.052572
28869,feat&fix(tokenization): add new consistent API for encoding and decoding related methods.,1238,True,False,,2024-04-07T08:04:46Z,1,2,8,6,1057,117,1174,6828185.052572
30300,Fix donut token2json multiline,954,True,True,2024-04-18T08:30:40Z,2024-04-18T08:30:40Z,1,3,2,2,7,1,8,594924.052572
30256,Add Flash Attention 2 to M2M100 model,664,True,True,2024-04-18T08:27:59Z,2024-04-18T08:27:59Z,9,4,6,5,379,14,393,777284.052572
30070,Re-enable SDPA's FA2 path,380,True,True,2024-04-17T20:21:00Z,2024-04-17T20:21:00Z,21,5,4,5,176,60,236,1648461.052572
29890,Add OLMo model family,1109,True,True,2024-04-17T15:59:07Z,2024-04-17T15:59:07Z,28,3,16,32,2482,3,2485,2465293.052572
18559,[WIP]Add TF BEiT Implementation,776,True,False,,2024-04-17T12:50:24Z,20,5,161,17,4794,35,4829,53823838.052572
30289,Upgrading to tokenizers 0.19.0,841,True,True,2024-04-17T15:17:50Z,2024-04-17T15:17:50Z,2,4,1,4,26,13,39,626566.052572
